{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "005f3e0d-8bec-413b-90a4-a11249e8b1bb",
   "metadata": {},
   "source": [
    "<h4>Data and Module Importing</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2e5bc1f-f87a-4ec6-beee-6fe6aa562326",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2864, 21)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tools\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\Toby\\\\Documents\\\\Digital Futures\\\\Projects\\\\WHO Project\\\\Life Expectancy Data.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597bffc3-eb32-4c7e-b94c-bec97efc81f0",
   "metadata": {},
   "source": [
    "<h4>Train-Test Split</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f8959a-9bf8-410e-a919-a8dd6f0c4471",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "feature_cols = list(df.columns)\n",
    "feature_cols.remove('Life_expectancy')\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df['Life_expectancy']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7366d3-feef-4b69-8425-c9e3d7f2d10c",
   "metadata": {},
   "source": [
    "<h2>Interactive Model Selection and Outputs</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "e69df860-815f-4461-82b0-ac8fc7ce3b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to run the full model (1) or run a censored model to cover sensitive data (2)?\n",
      "    Enter your option here:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following shows the level of success our full model has with predicting life expectancy:\n",
      "\n",
      "\n",
      "P-Values:\n",
      "\n",
      "const                                   0.000\n",
      "Year                                    0.000\n",
      "Under_five_deaths                       0.000\n",
      "Adult_mortality                         0.000\n",
      "Alcohol_consumption                     0.057\n",
      "Hepatitis_B                             0.002\n",
      "BMI                                     0.000\n",
      "Polio                                   0.000\n",
      "Diphtheria                              0.014\n",
      "Incidents_HIV                           0.000\n",
      "Thinness_ten_nineteen_years             0.001\n",
      "Schooling                               0.000\n",
      "Economy_status_Developed                0.000\n",
      "Region_Asia                             0.032\n",
      "Region_Central America and Caribbean    0.000\n",
      "Region_European Union                   0.000\n",
      "Region_Middle East                      0.115\n",
      "Region_North America                    0.006\n",
      "Region_Oceania                          0.000\n",
      "Region_Rest of Europe                   0.000\n",
      "Region_South America                    0.000\n",
      "log_GDP                                 0.000\n",
      "dtype: float64\n",
      "\n",
      "R-Squared:\n",
      "    \n",
      "0.9835984532011136\n",
      "    \n",
      "AIC and BIC:\n",
      "    \n",
      "7390.805609995028\n",
      "7517.013971009005\n",
      "    \n",
      "Condition Number:\n",
      "    \n",
      "12.705236589289497\n",
      "\n",
      "RMSE:\n",
      "\n",
      "1.2025776779399533\n",
      "\n",
      "{'const': 68.868, 'Year': 0.1834, 'Under_five_deaths': -3.4189, 'Adult_mortality': -5.3247, 'Alcohol_consumption': -0.089, 'Hepatitis_B': -0.1266, 'BMI': -0.4056, 'Polio': 0.3417, 'Diphtheria': -0.228, 'Incidents_HIV': 0.1931, 'Thinness_ten_nineteen_years': -0.1251, 'Schooling': 0.2649, 'Economy_status_Developed': 1.0693, 'Region_Asia': 0.0844, 'Region_Central America and Caribbean': 0.5687, 'Region_European Union': -0.2343, 'Region_Middle East': 0.0585, 'Region_North America': 0.0846, 'Region_Oceania': -0.2057, 'Region_Rest of Europe': 0.1471, 'Region_South America': 0.3875, 'log_GDP': 0.652}\n",
      "\n",
      "For comparison, the optimal condition number found using VIF is 6.59316008302239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Toby\\AppData\\Local\\Temp\\ipykernel_31056\\1675785992.py:40: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  coef_df = pd.read_html(results.summary().tables[1].as_html(),header=0,index_col=0)[0]\n"
     ]
    }
   ],
   "source": [
    "model_selection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d28693-7344-487c-a3fe-569e92855670",
   "metadata": {},
   "source": [
    "<h4>Behind the Scenes Workings</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "b3b8c152-b0b1-4890-99a2-d20f8b9b73ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_selection():\n",
    "\n",
    "    # Error Handling\n",
    "    \n",
    "    try: model_choice = int(input(\"\"\"Do you want to run the full model (1) or run a censored model to cover sensitive data (2)?\n",
    "    Enter your option here: \"\"\"))\n",
    "    except:\n",
    "        print(\"Invalid input. Please enter either 1 or 2 to choose your model\")\n",
    "        model_selection()\n",
    "\n",
    "    if model_choice == 1:\n",
    "\n",
    "    # Model FE and defining stage\n",
    "    \n",
    "        X_train_fe = feature_eng_full(X_train)\n",
    "        model_cols = X_train_fe.columns\n",
    "\n",
    "    # Model Metrics\n",
    "        global model_state\n",
    "        model_state = \"full\"\n",
    "        modelling(model_cols)\n",
    "        print()\n",
    "        print(coefficients) \n",
    "        print() \n",
    "\n",
    "        lin_reg = sm.OLS(y_train, X_train_fe[optimal_cols])\n",
    "        results = lin_reg.fit()\n",
    "        print(f\"For comparison, the optimal condition number found using VIF is {results.condition_number}\")\n",
    "\n",
    "\n",
    "    elif model_choice == 2:\n",
    "        print(\"This is a placeholder for the sensitive model\")\n",
    "    else:\n",
    "        print(\"This is not one of the options. Please enter either 1 or 2 to choose your model\")\n",
    "        model_selection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "9792513e-770d-40d7-bcae-20706702e7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_eng_full(data):\n",
    "    data = data.copy()\n",
    "\n",
    "    # Removing autocorrelated columns\n",
    "    \n",
    "    data = data.drop(columns = ['Country', 'Economy_status_Developing', 'Infant_deaths'])\n",
    "    \n",
    "    # One hot encoding\n",
    "    \n",
    "    data = pd.get_dummies(data, columns = ['Region'], drop_first = True, prefix = 'Region', dtype=int) \n",
    "\n",
    "    # Fixing exponential relationship\n",
    "\n",
    "    data['log_GDP'] =  np.log(data['GDP_per_capita'])\n",
    "\n",
    "    # Scaling\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    data[data.columns] = scaler.fit_transform(data[data.columns])\n",
    "\n",
    "    # Removing columns we are not interested in for our model\n",
    "\n",
    "    data = data.drop(columns = ['Measles', 'GDP_per_capita', 'Population_mln', 'Thinness_five_nine_years'])\n",
    "    \n",
    "    # VIF\n",
    "\n",
    "    data_col = data.columns\n",
    "    \n",
    "    calculate_vif(data[data_col])\n",
    "    \n",
    "    data = sm.add_constant(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4faed6ae-1f88-4f96-bfdb-cedf6df22e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vif(X, thresh = 5.0):\n",
    "    variables = list(range(X.shape[1]))\n",
    "    dropped = True\n",
    "    while dropped:\n",
    "        dropped = False\n",
    "        # this bit uses list comprehension to gather all the VIF values of the different variables\n",
    "        vif = [variance_inflation_factor(X.iloc[:, variables].values, ix)\n",
    "               for ix in range(X.iloc[:, variables].shape[1])]\n",
    "        \n",
    "        maxloc = vif.index(max(vif)) # getting the index of the highest VIF value\n",
    "        if max(vif) > thresh:\n",
    "            del variables[maxloc] # we delete the highest VIF value on condition that it's higher than the threshold\n",
    "            dropped = True # if we deleted anything, we set the 'dropped' value to True to stay in the while loop    \n",
    "    \n",
    "    global optimal_cols \n",
    "    optimal_cols = list(X.columns[variables])\n",
    "    optimal_cols.append('const')\n",
    "\n",
    "    # We now create a global variable and assign the list of columns still in the valid set to it, remembering to add the constant back in. We can use this to check for an optimal condition number.\n",
    "    \n",
    "    return optimal_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "c03312c3-8d79-470d-8c32-d4c5d91ccc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelling(col):\n",
    "\n",
    "    # Modelling Stage\n",
    "    \n",
    "    lin_reg = sm.OLS(y_train, X_train_fe[col])\n",
    "    results = lin_reg.fit()\n",
    "\n",
    "    # Metrics Observations \n",
    "    \n",
    "    print(f\"\\nThe following shows the level of success our {model_state} model has with predicting life expectancy:\\n\")\n",
    "    print(f\"\"\"\n",
    "P-Values:\n",
    "\n",
    "{round(results.pvalues,3)}\n",
    "\n",
    "R-Squared:\n",
    "    \n",
    "{results.rsquared}\n",
    "    \n",
    "AIC and BIC:\n",
    "    \n",
    "{results.aic}\n",
    "{results.bic}\n",
    "    \n",
    "Condition Number:\n",
    "    \n",
    "{results.condition_number}\n",
    "\"\"\")\n",
    "\n",
    "    # Coefficient\n",
    "    # print()\n",
    "    # coefficients = results.params\n",
    "    # print(list(coefficients))\n",
    "    # print()\n",
    "\n",
    "    # From stackoverflow.com - user idiot-tom\n",
    "\n",
    "    global coef_df\n",
    "    global coefficients\n",
    "    coef_df = pd.read_html(results.summary().tables[1].as_html(),header=0,index_col=0)[0]\n",
    "    # a=coef_df['coef'].values[1]\n",
    "    # c=coef_df['coef'].values[0]\n",
    "    coefficients = coef_df['coef'].to_dict()\n",
    "    \n",
    "    # RMSE Calculations\n",
    "    \n",
    "    y_pred = results.predict(X_train_fe[col])\n",
    "    rmse = statsmodels.tools.eval_measures.rmse(y_train, y_pred)\n",
    "    print(f\"RMSE:\\n\\n{rmse}\")\n",
    "    # print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "fcd3e6bf-e93d-4a4f-8079-6edfd6679e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_inputs_1():\n",
    "\n",
    "    # List of features included in our final full model\n",
    "    \n",
    "    user_values = ['year', 'U5 Deaths per 1000', 'adult mortality rate',\n",
    "       'alcohol consumption', 'hepatitis B immunization (%)', 'BMI', 'polio immunization (%)',\n",
    "       'diphtheria immunization (%)', 'HIV per 1000', \n",
    "       'thinness between 10-19', 'schooling years',\n",
    "       'economy status (Developed or Developing)', 'region', 'GDP']\n",
    "\n",
    "    # Initialise a dictionary to store the users inputs\n",
    "    \n",
    "    user_dict = {}\n",
    "\n",
    "    # Define lists to use in input checking - these features are grouped by the upper limit of their input\n",
    "    \n",
    "    limit100 = ['U5 Deaths per 1000', 'adult mortality rate', 'HIV per 1000']\n",
    "    limit1000 = ['hepatitis B immunization (%)', 'polio immunization (%)', 'diphtheria immunization (%)', 'thinness between 10-19']\n",
    "    regions = \n",
    "\n",
    "    # Section used to take in user inputs\n",
    "\n",
    "    for each in user_values:       # Creates a new input for every feature in the model\n",
    "\n",
    "        # For features that require text inputs, a regular input is used. Once an input is taken, it is added into the dictionary under the respective feature.\n",
    "        \n",
    "        if each in ['economy status (Developed or Developing)', 'region']:\n",
    "            user_input = input(f\"Please enter your value for {each}: \")\n",
    "            user_dict[each] = user_input\n",
    "\n",
    "        # For features that require an integer input, there is some checking that must be done. The try exception ensures that only numbers can be used as an input and it will keep asking for\n",
    "        # a number until the user inputs one.\n",
    "        \n",
    "        else:\n",
    "            while True:\n",
    "                try:\n",
    "                    user_input = int(input(f\"Please enter your value for {each}: \"))\n",
    "\n",
    "                    # This section is used for data checking too. Some features have maximum limits for them to make sense (E.g. You cannot have 101% of a population!). This is where\n",
    "                    # the inputs are checked to ensure they follow the rules.\n",
    "                    \n",
    "                    if each in limit100 and user_input > 100:\n",
    "                        print(f\"{each.title()} must be less than 100, please enter a new value\")\n",
    "                    elif each in limit1000 and user_input > 1000:\n",
    "                        print(f\"{each.title()} must be less than 1000, please enter a new value\")\n",
    "\n",
    "                    # Once the user has entered a valid input, it is entered into the dictionary and the checks are ended. It then moves onto the next input (or ends if it is the last input)\n",
    "                    \n",
    "                    else:\n",
    "                        user_dict[each] = user_input\n",
    "                        break\n",
    "                except:\n",
    "                    print(\"This must be an integer, try again\")\n",
    "\n",
    "    # Prints the dictionary of the user's inputs\n",
    "            \n",
    "    for a, b in user_dict.items():\n",
    "        print(f\"{a.title()}: {b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54651344-e1a6-4f74-8793-a72699ff157a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_inputs_1()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
